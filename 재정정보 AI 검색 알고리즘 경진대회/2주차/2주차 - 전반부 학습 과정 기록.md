
<br>

## 전반부 과정

```
1. Document Load
	1. 일반적인 형식의 문서를 로드 한다.
2. Split Chunk
	1. 문서에 적힌 글을 하나의 단위로 분할(Split)한다.
	2. 고정 크기 / 문단 기반 / 의미 기반 / 문장 기반 / 슬라이딩 윈도우
3.  Chunk Embedding
	1. 쪼개진 단위의 덩어리(chunk)를 숫자로 이루어진 벡터로 변환한다.
	2. 비슷한 의미를 가진 단어나 문장은 벡터 공간에서 가까운 위치에 있게 된다.("고양이"와 "猫"(일본어로 고양이)는 다른 언어지만 비슷한 벡터 표현)
4. Vector Database
	1. 벡터로 변한 데이터를 효율적으로 다루기 위한 공간으로 이동.
	2. 벡터 자체 유사성이 설정된 채로 DB에 넣기 때문에 검색이 빠르다. 
```

<br>

### Split Chunk

- 고정 크기 정규:
    - 방법: 일정한 크기의 텍스트 덩어리로 분할.
    - 예: 500자 또는 100단어마다 분할
    - 장점: 구현이 간단하고 일관된 크기의 청크를 생성.
    - 단점: 문맥이나 의미를 고려하지 않아 중요한 정보가 분리될 수 있다.
- 문단 기반 분할:
    - 방법: 문단 단위로 텍스트를 분할.
    - 장점: 자연스러운 의미 단위를 유지할 수 있다.
    - 단점: 문단 길이가 일정하지 않아 처리에 어려움이 있을 수 있다.
- 의미 기반 분할:
    - 방법: 텍스트의 의미나 주제를 고려하여 분할.
    - 기술: 토픽 모델링, 키워드 추출 등의 NLP 기술을 활용.
    - 장점: 의미적으로 일관된 청크를 생성할 수 있다.
    - 단점: 구현이 복잡하고 계산 비용이 높을 수 있다.
- 문장 기반 분할:
    - 방법: 문장 단위로 텍스트를 나눔.
    - 장점: 문법적으로 완전한 단위를 유지할 수 있다.
    - 단점: 문장 길이가 다양하여 일관성이 떨어질 수 있다.
- 슬라이딩 윈도우 기법:
    - 방법: 일정 크기의 윈도우를 겹치게 이동하며 텍스트를 분할.
    - 예: 100단어 윈도우를 50단어씩 겹치게 이동
    - 장점: 문맥의 연속성을 유지하면서 분할할 수 있다.
    - 단점: 중복된 내용이 생길 수 있어 처리 시 주의가 필요.

<br>

### 임베딩(Embedding)

- Pre-trained 언어 모델: 사전 학습된 언어 모델을 사용하여 임베딩 생성
- Multilingual 모델: 여러 언어를 지원하는 모델 사용
- 도메인 특화 모델: 특정 도메인에 최적화된 모델 사용
- 커스텀 트레이닝 모델: 사용자 정의 데이터로 재학습한 모델 사용

### 벡터DB(Vector Store)

- FAISS: 빠르고 효율적인 벡터 검색 및 인덱싱
- Annoy: 대규모 데이터셋에서 빠른 검색 가능
- HNSWlib: 고성능과 높은 정확도의 검색 제공
- Milvus: 대규모 벡터 데이터베이스 관리 및 검색 지원
